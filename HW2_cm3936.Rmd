---
title: "HW2"
author: "Carolyn Martinez"

date: "2024-09-29"
output: github_document
--- 

```{r adding libraries}
library(readxl)
library(tidyverse)
library(dplyr)
library(readr)
```

**Problem 1: NYC Transit Data**
```{r reading in the data, results= 'hide'}
nyvtransit = read_csv("subwaydata1.csv", 
                       na = c("NA", ".", ""),
                      col_types = cols(
                         `Route8` = col_character(),
                       `Route9` = col_character(),
                     `Route10` = col_character(),
                      `Route11` = col_character()))


nyvtransit = janitor::clean_names(nyvtransit)
```

```{r selecting and new vars}
select(nyvtransit, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada)

nyvtransit %>%
  mutate(
    entry = case_match(entry, "YES" ~ 1, "NO" ~ 0, .default=as.logical(NA))
  )
```

The data set contains various variables about the subway stops in the New York City subway stations and their locations. The variables include the line, station name, latitude and longitude, the route it runs on, whether it is compliant with the ADA, whether it travels north to south or east to west. The data set after my cleaning steps includes the line, name of the station, the latitude and longitude of the station, the routes, entry, vending and the type of entrance. My data cleaning steps include the cleaning up the names of the columns using the 'janitor' package, removing the rows with missing variables, selecting specific variables to view, and changing the entry variable from a character to a logical variable. The remaining rows and columns are the stations and the variables: line, name of the station, the latitude and longitude of the station, the routes, entry, vending and the type of entrance, repectively. 

**How many distinct stations are there?**
```{r distinct stations first, results= 'hide'}

distinct(nyvtransit, .keep_all = FALSE)

```

There are 1868 distinct train stations in NYC. 

**How many stations are ADA compliant?**
```{r ADA compliant, results='hide'}

nyvtransit %>%
  mutate(
    ada = case_match(ada, TRUE ~ 1, FALSE ~ 0, .default=as.logical(NA))
  )

filter(nyvtransit, ada==1)

```
There are 468 stations that are ADA compliant. 

**What proportion of station entrances/exits without vending allow entrance?**

```{r entrance, results= 'hide'}

no_vending=filter(nyvtransit,vending=="NO")
  
filter(no_vending,entry=="YES")
  

```

The proportion of station entrances/exits without vending that allow entrance is 0.38. 

**How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?**
```{r distinct stations, results= 'hide'}

nyvtransit_pivotlong = 
  pivot_longer(
    nyvtransit, 
    route1:route11,
    names_to = "routenumber", 
    values_to = "routename")
  
nyvtransit_pivotlong_distinct = distinct(nyvtransit_pivotlong, station_name, .keep_all = TRUE)

nyvtransit_pivotlong_distinctADA=
   filter(nyvtransit_pivotlong,  routename =="A", ada==1) %>%
   distinct(station_name, .keep_all = TRUE )
  
  
```

There are 16 distinct stations that serve the A train and that are ADA compliant. There are 356 distinct stations that serve the A train. 

**Problem 2**

```{r importing Mr Trash data}
mrtrashwheel = read_xlsx("./trash_wheel_collection_data1.xlsx", 
                       sheet = "Mr. Trash Wheel",
                        range = "A2:N586",
                        col_names = TRUE,
                        na = "",
                        .name_repair = "unique") |>
                         janitor::clean_names() |>
                        mutate( wheel = 'mrtrashwheel') |> 
                        mutate( sports_balls_round = (round(sports_balls)))

```

```{r importing professor trash}
professortrash = read_xlsx("./trash_wheel_collection_data1.xlsx", 
                        sheet = "Professor Trash Wheel",
                        range = "A2:M108",
                        col_names = TRUE,
                        col_types = c("guess"),
                        na = "",
                        .name_repair = "unique") |>
                         janitor::clean_names() |>
                         mutate( wheel = 'professortrash')
```

```{r importing gwynnda trash}
gwynndatrash = read_xlsx("./trash_wheel_collection_data1.xlsx", 
                        sheet = "Gwynnda Trash Wheel",
                        range = "A2:L157",
                        col_names = TRUE,
                        col_types = c("guess"),
                        na = "",
                        .name_repair = "unique") |>
                        janitor::clean_names() |>
                        mutate( wheel = 'gwynndatrash')
```
```{r changing all years into the same class}
gwynndatrash = gwynndatrash |> mutate(year = as.character(year))
professortrash = professortrash |> mutate(year = as.character(year))
mrtrashwheel = mrtrashwheel |> mutate(year = as.character(year))
```

```{r binding everything}
alltrashwheels = 
  bind_rows(gwynndatrash, professortrash, mrtrashwheel)|>
  janitor::clean_names() 
```

```{r total weight}
total_weight = sum(alltrashwheels$weight_tons[alltrashwheels$wheel == "professortrash"], na.rm = TRUE)

total_cigs = sum(alltrashwheels$cigarette_butts[alltrashwheels$wheel =="gwynndatrash"] [alltrashwheels$year == "2022"], na.rm=TRUE)
```

There are 845 total observations with key variables that include the dumpster number, month, year, date, and other variables quantifying the varity of trash collected in each dumpster. The total weight in tons of trash collected by Professor Trash Wheel in 2022 was `r total_weight`. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r total_cigs`. 

**Problem 3**

```{r importing and cleaning the data sets}

bakers = read_csv("./gbb_datasets/bakers.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |>
  rename(baker=baker_name)|>
  drop_na() |>
  separate(baker, into = c("baker", "last_name"), sep=" ", extra = "merge", fill = "right")

bakes = read_csv("./gbb_datasets/bakes.csv", na = c("NA", "", ".")) |>
janitor::clean_names()

results =
  read_excel("./gbb_datasets/results.xls", na = c("NA", "", "."),
           sheet= "results",
           range = "A3:E1139",
           col_types = c("guess")) |>
            janitor::clean_names()|>
            drop_na()
```

```{r merge , echo=TRUE}

results_bakes_bakers=
  bakes|>
left_join(results, by = c("baker","series","episode"))|>
  left_join(bakers, by = c("baker","series"))|>
  drop_na()

write.csv(results_bakes_bakers, file = "./gbb_datasets/results_bakes_bakers.csv", row.names = FALSE)
```

For the data cleaning process, I cleaned the names using the `janitor` package, renaming and arrnaging the columns to prepare to merge, and finally removing the rows with missing data. Then the merging of the data to create one cohesive dataset required the changing of column names to have oone common column among all the individual datasets. The final data set has all the relevant variables and each showstopper and bake is an individual data point. I wonder if there were any changes to the data set such as pivots to make the bakers into the columms. I still do not know when to make this decision and I would like more examples and scenarios where this is best. 



```{r star baker, echo=FALSE}
star_bakers = results_bakes_bakers |>
  filter(series >= 5 & series <= 10)|>
  filter(result %in% c("STAR BAKER","WINNER")) |>
  select(baker, series, episode, result)|>
  arrange(series, episode)

print(star_bakers)
```

The overall winners were not surprising because they were consistently named star baker. Not many winners were surprising because they followed the pattern of being consecutive star baker and being declared winner. 


```{r viewers}
viewers = read_csv("./gbb_datasets/viewers.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |>
    drop_na()

print(viewers)

```

The average viewership for season 1 is `r mean(viewers$series_1)` and for season 5 it is `r mean(viewers$series_5)`.




